{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fraud Detectin.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtFzmGe1XRPH"
      },
      "source": [
        "# Credit Card Fraud Detection::¶\n",
        "## Download dataset from this link:\n",
        "\n",
        "https://www.kaggle.com/mlg-ulb/creditcardfraud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1VLPPQFHBxq"
      },
      "source": [
        "# Credit Card Fraud Detection::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzUagRcJHGV-"
      },
      "source": [
        "### Description about dataset::\n",
        "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, … V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning.\n",
        "\n",
        "Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.¶"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55WTseUfHNH4"
      },
      "source": [
        "# WORKFLOW :\n",
        "1.Load Data\n",
        "\n",
        "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
        "\n",
        "3.Standardized the Input Variables.\n",
        "\n",
        "4.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
        "\n",
        "5.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
        "\n",
        "6.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
        "\n",
        "7.Train the Model with Epochs (100).\n",
        "\n",
        "8.If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
        "\n",
        "9.Prediction should be > 92% \n",
        "\n",
        "10.Evaluation Step \n",
        "\n",
        "11.Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqbYh2AuHPLj"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbeS9rmOWZTJ"
      },
      "source": [
        "\n",
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snAt6rWyHZ40"
      },
      "source": [
        "df = pd.read_csv(\"creditcard.csv\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "DAh8D9roxHGl",
        "outputId": "128d7e3c-6955-4d55-b1e6-50bc8156cafb"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO0a__oGx2rl",
        "outputId": "7aed56f2-165a-4ef6-e1f6-fac5848dacde"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "Amount    0\n",
              "Class     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i74UM567yJUQ",
        "outputId": "a6893a1a-a5ba-4652-961e-25c8cb033f88"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBbiwRtWyWWS",
        "outputId": "a7f1a75d-7e02-4791-d7af-fdbb9a7f119e"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0e93Gevydx6",
        "outputId": "68d5e496-38d6-4f09-b6b1-f7fab04a5d0f"
      },
      "source": [
        "df[\"Class\"].value_counts()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-epIwXJO3w3t",
        "outputId": "035b413e-7f23-4876-a408-cbebf0099d04"
      },
      "source": [
        "284315*0.5"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "142157.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDMGoit52cys"
      },
      "source": [
        "x_train = df[:142400]\n",
        "x_test = df[142400:227840]\n",
        "x_val = df[227840:]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olMn-BkQ4SCC"
      },
      "source": [
        "\n",
        "\n",
        "y = df['Class']\n",
        "y_train = y[:142400]\n",
        "y_test = y[142400:227840]\n",
        "y_val = y[227840:]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_2wFevc3kSU"
      },
      "source": [
        "#Standardizing data\n",
        "mean = x_train.mean()\n",
        "std = x_train.std()\n",
        "\n",
        "x_train -= mean\n",
        "x_train /= std\n",
        "\n",
        "x_test -= mean\n",
        "x_test  /= std"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "nUNKyRk04kLY",
        "outputId": "19ac0774-dc74-46a0-e301-1988e95dbac0"
      },
      "source": [
        "x_train.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.483019</td>\n",
              "      <td>-0.612145</td>\n",
              "      <td>-0.058089</td>\n",
              "      <td>1.471230</td>\n",
              "      <td>0.938453</td>\n",
              "      <td>-0.042449</td>\n",
              "      <td>0.299511</td>\n",
              "      <td>0.306998</td>\n",
              "      <td>0.027356</td>\n",
              "      <td>0.415433</td>\n",
              "      <td>0.108154</td>\n",
              "      <td>-0.725030</td>\n",
              "      <td>-0.636121</td>\n",
              "      <td>-0.974568</td>\n",
              "      <td>-0.370131</td>\n",
              "      <td>1.339127</td>\n",
              "      <td>-0.526545</td>\n",
              "      <td>0.187379</td>\n",
              "      <td>0.131656</td>\n",
              "      <td>0.520659</td>\n",
              "      <td>0.290736</td>\n",
              "      <td>0.029732</td>\n",
              "      <td>0.623656</td>\n",
              "      <td>-0.130907</td>\n",
              "      <td>0.093447</td>\n",
              "      <td>-0.005391</td>\n",
              "      <td>-0.427881</td>\n",
              "      <td>0.341806</td>\n",
              "      <td>-0.076157</td>\n",
              "      <td>0.239109</td>\n",
              "      <td>-0.043504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2.483019</td>\n",
              "      <td>0.794456</td>\n",
              "      <td>0.152387</td>\n",
              "      <td>-0.400677</td>\n",
              "      <td>0.235167</td>\n",
              "      <td>0.262784</td>\n",
              "      <td>-0.125227</td>\n",
              "      <td>0.033817</td>\n",
              "      <td>0.016334</td>\n",
              "      <td>-0.152498</td>\n",
              "      <td>-0.136842</td>\n",
              "      <td>1.339321</td>\n",
              "      <td>1.015551</td>\n",
              "      <td>0.508989</td>\n",
              "      <td>-0.187793</td>\n",
              "      <td>0.439447</td>\n",
              "      <td>0.538503</td>\n",
              "      <td>-0.177531</td>\n",
              "      <td>-0.119679</td>\n",
              "      <td>-0.159276</td>\n",
              "      <td>-0.154748</td>\n",
              "      <td>-0.257942</td>\n",
              "      <td>-0.820551</td>\n",
              "      <td>0.228101</td>\n",
              "      <td>-0.589372</td>\n",
              "      <td>0.082946</td>\n",
              "      <td>0.211891</td>\n",
              "      <td>-0.024930</td>\n",
              "      <td>0.040681</td>\n",
              "      <td>-0.357048</td>\n",
              "      <td>-0.043504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.482971</td>\n",
              "      <td>-0.611344</td>\n",
              "      <td>-0.845130</td>\n",
              "      <td>0.868444</td>\n",
              "      <td>0.183461</td>\n",
              "      <td>-0.168789</td>\n",
              "      <td>1.342831</td>\n",
              "      <td>0.780483</td>\n",
              "      <td>0.148123</td>\n",
              "      <td>-1.307443</td>\n",
              "      <td>0.219213</td>\n",
              "      <td>0.396744</td>\n",
              "      <td>0.035019</td>\n",
              "      <td>0.737660</td>\n",
              "      <td>-0.211946</td>\n",
              "      <td>2.287505</td>\n",
              "      <td>-3.284790</td>\n",
              "      <td>1.207120</td>\n",
              "      <td>-0.045172</td>\n",
              "      <td>-2.776327</td>\n",
              "      <td>0.670991</td>\n",
              "      <td>0.398989</td>\n",
              "      <td>1.401837</td>\n",
              "      <td>1.598148</td>\n",
              "      <td>-1.175939</td>\n",
              "      <td>-1.048524</td>\n",
              "      <td>-0.326296</td>\n",
              "      <td>-0.144231</td>\n",
              "      <td>-0.202537</td>\n",
              "      <td>1.168421</td>\n",
              "      <td>-0.043504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.482971</td>\n",
              "      <td>-0.395209</td>\n",
              "      <td>-0.127917</td>\n",
              "      <td>0.884071</td>\n",
              "      <td>-0.756575</td>\n",
              "      <td>0.208895</td>\n",
              "      <td>0.911429</td>\n",
              "      <td>0.305291</td>\n",
              "      <td>0.253311</td>\n",
              "      <td>-1.190382</td>\n",
              "      <td>-0.030371</td>\n",
              "      <td>-0.414935</td>\n",
              "      <td>0.145074</td>\n",
              "      <td>0.527689</td>\n",
              "      <td>-0.344811</td>\n",
              "      <td>-0.929574</td>\n",
              "      <td>-1.198239</td>\n",
              "      <td>-0.821131</td>\n",
              "      <td>2.462906</td>\n",
              "      <td>-1.503422</td>\n",
              "      <td>-0.347893</td>\n",
              "      <td>-0.095052</td>\n",
              "      <td>0.194158</td>\n",
              "      <td>-0.266275</td>\n",
              "      <td>-1.992242</td>\n",
              "      <td>1.181015</td>\n",
              "      <td>-0.494525</td>\n",
              "      <td>0.159558</td>\n",
              "      <td>0.193300</td>\n",
              "      <td>0.133129</td>\n",
              "      <td>-0.043504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.482924</td>\n",
              "      <td>-0.501028</td>\n",
              "      <td>0.532180</td>\n",
              "      <td>0.691123</td>\n",
              "      <td>0.201046</td>\n",
              "      <td>-0.095224</td>\n",
              "      <td>0.013779</td>\n",
              "      <td>0.610157</td>\n",
              "      <td>-0.271957</td>\n",
              "      <td>0.831791</td>\n",
              "      <td>0.737618</td>\n",
              "      <td>-0.983744</td>\n",
              "      <td>0.498333</td>\n",
              "      <td>1.367523</td>\n",
              "      <td>-1.250796</td>\n",
              "      <td>-0.058074</td>\n",
              "      <td>-0.504942</td>\n",
              "      <td>-0.315715</td>\n",
              "      <td>0.054766</td>\n",
              "      <td>1.014733</td>\n",
              "      <td>0.509145</td>\n",
              "      <td>0.042040</td>\n",
              "      <td>1.443751</td>\n",
              "      <td>-0.176655</td>\n",
              "      <td>0.218234</td>\n",
              "      <td>-0.770392</td>\n",
              "      <td>0.976340</td>\n",
              "      <td>0.562719</td>\n",
              "      <td>0.695227</td>\n",
              "      <td>-0.083984</td>\n",
              "      <td>-0.043504</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time        V1        V2  ...       V28    Amount     Class\n",
              "0 -2.483019 -0.612145 -0.058089  ... -0.076157  0.239109 -0.043504\n",
              "1 -2.483019  0.794456  0.152387  ...  0.040681 -0.357048 -0.043504\n",
              "2 -2.482971 -0.611344 -0.845130  ... -0.202537  1.168421 -0.043504\n",
              "3 -2.482971 -0.395209 -0.127917  ...  0.193300  0.133129 -0.043504\n",
              "4 -2.482924 -0.501028  0.532180  ...  0.695227 -0.083984 -0.043504\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNvE9Je-4oKt"
      },
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-LxP52j4wxZ"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, activation='relu', kernel_regularizer=l2(0.001), input_shape=(x_train.shape[1],)))\n",
        "model.add(layers.Dense(8, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8KAMQ4j5TsD"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpfmrxzA5gGu",
        "outputId": "3e70ac9e-ad8f-478c-8b6c-6126a598459a"
      },
      "source": [
        "network_history = model.fit(x_train, y_train, epochs=100, batch_size=500, validation_data=(x_val, y_val))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "285/285 [==============================] - 2s 3ms/step - loss: 0.7247 - accuracy: 0.4930 - val_loss: 173.1344 - val_accuracy: 0.9987\n",
            "Epoch 2/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.9996 - val_loss: 241.7223 - val_accuracy: 0.9987\n",
            "Epoch 3/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0352 - accuracy: 0.9999 - val_loss: 236.7598 - val_accuracy: 0.9987\n",
            "Epoch 4/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 215.9140 - val_accuracy: 0.9987\n",
            "Epoch 5/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 187.3443 - val_accuracy: 0.9987\n",
            "Epoch 6/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 150.8139 - val_accuracy: 0.9987\n",
            "Epoch 7/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 115.0176 - val_accuracy: 0.9987\n",
            "Epoch 8/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 81.0757 - val_accuracy: 0.9987\n",
            "Epoch 9/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 51.9917 - val_accuracy: 0.9987\n",
            "Epoch 10/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 29.8281 - val_accuracy: 0.9987\n",
            "Epoch 11/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 16.1712 - val_accuracy: 0.9987\n",
            "Epoch 12/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 8.0746 - val_accuracy: 0.9987\n",
            "Epoch 13/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.9446 - val_accuracy: 0.9987\n",
            "Epoch 14/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3244 - val_accuracy: 0.9987\n",
            "Epoch 15/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6389 - val_accuracy: 0.9987\n",
            "Epoch 16/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9987\n",
            "Epoch 17/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0672 - val_accuracy: 0.9987\n",
            "Epoch 18/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.9987\n",
            "Epoch 19/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.9987\n",
            "Epoch 20/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1064 - val_accuracy: 0.0013\n",
            "Epoch 21/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7065 - val_accuracy: 0.9987\n",
            "Epoch 22/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9987\n",
            "Epoch 23/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 9.1364e-04 - accuracy: 1.0000 - val_loss: 0.4572 - val_accuracy: 0.9987\n",
            "Epoch 24/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 8.2558e-04 - accuracy: 1.0000 - val_loss: 0.7615 - val_accuracy: 0.9987\n",
            "Epoch 25/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 7.4875e-04 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9987\n",
            "Epoch 26/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 6.8262e-04 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9987\n",
            "Epoch 27/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 6.2370e-04 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9987\n",
            "Epoch 28/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 5.7422e-04 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.9987\n",
            "Epoch 29/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 5.2527e-04 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.9986\n",
            "Epoch 30/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 4.8755e-04 - accuracy: 1.0000 - val_loss: 0.4916 - val_accuracy: 0.9987\n",
            "Epoch 31/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 4.5393e-04 - accuracy: 1.0000 - val_loss: 0.7335 - val_accuracy: 0.9987\n",
            "Epoch 32/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 4.1881e-04 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9987\n",
            "Epoch 33/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 3.9250e-04 - accuracy: 1.0000 - val_loss: 0.6205 - val_accuracy: 0.9987\n",
            "Epoch 34/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 3.6829e-04 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.0013\n",
            "Epoch 35/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 3.4571e-04 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9987\n",
            "Epoch 36/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 3.2540e-04 - accuracy: 1.0000 - val_loss: 0.8617 - val_accuracy: 0.0013\n",
            "Epoch 37/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 3.0659e-04 - accuracy: 1.0000 - val_loss: 2.0620 - val_accuracy: 0.9987\n",
            "Epoch 38/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 2.8956e-04 - accuracy: 1.0000 - val_loss: 12.7209 - val_accuracy: 0.0013\n",
            "Epoch 39/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 2.7723e-04 - accuracy: 1.0000 - val_loss: 1.0782 - val_accuracy: 0.9987\n",
            "Epoch 40/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 2.6252e-04 - accuracy: 1.0000 - val_loss: 6.6494 - val_accuracy: 0.0013\n",
            "Epoch 41/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 2.5009e-04 - accuracy: 1.0000 - val_loss: 4.5051 - val_accuracy: 0.0013\n",
            "Epoch 42/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 2.4274e-04 - accuracy: 1.0000 - val_loss: 273.1871 - val_accuracy: 0.0013\n",
            "Epoch 43/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 2.3172e-04 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9987\n",
            "Epoch 44/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 2.2160e-04 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 0.9987\n",
            "Epoch 45/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 2.1522e-04 - accuracy: 1.0000 - val_loss: 398.1741 - val_accuracy: 0.0013\n",
            "Epoch 46/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 2.0810e-04 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9987\n",
            "Epoch 47/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 2.0080e-04 - accuracy: 1.0000 - val_loss: 0.6078 - val_accuracy: 0.9987\n",
            "Epoch 48/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.9614e-04 - accuracy: 1.0000 - val_loss: 166.9749 - val_accuracy: 0.0013\n",
            "Epoch 49/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.9091e-04 - accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.9987\n",
            "Epoch 50/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.8625e-04 - accuracy: 1.0000 - val_loss: 215.4695 - val_accuracy: 0.0013\n",
            "Epoch 51/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.8359e-04 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9987\n",
            "Epoch 52/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.7905e-04 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.9987\n",
            "Epoch 53/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.7648e-04 - accuracy: 1.0000 - val_loss: 99.8727 - val_accuracy: 0.0013\n",
            "Epoch 54/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.7348e-04 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9987\n",
            "Epoch 55/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.7033e-04 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9987\n",
            "Epoch 56/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.6760e-04 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9987\n",
            "Epoch 57/100\n",
            "285/285 [==============================] - 1s 3ms/step - loss: 1.6349e-04 - accuracy: 1.0000 - val_loss: 274.2643 - val_accuracy: 0.0013\n",
            "Epoch 58/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.6140e-04 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9987\n",
            "Epoch 59/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.5903e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9987\n",
            "Epoch 60/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.5656e-04 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.9987\n",
            "Epoch 61/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.5484e-04 - accuracy: 1.0000 - val_loss: 138.0661 - val_accuracy: 0.0013\n",
            "Epoch 62/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.5309e-04 - accuracy: 1.0000 - val_loss: 153.9267 - val_accuracy: 0.0013\n",
            "Epoch 63/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.5055e-04 - accuracy: 1.0000 - val_loss: 352.1515 - val_accuracy: 0.0013\n",
            "Epoch 64/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.4815e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9977\n",
            "Epoch 65/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.4612e-04 - accuracy: 1.0000 - val_loss: 0.7223 - val_accuracy: 0.9987\n",
            "Epoch 66/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.4326e-04 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9987\n",
            "Epoch 67/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.4164e-04 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9987\n",
            "Epoch 68/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.3943e-04 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9987\n",
            "Epoch 69/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.3756e-04 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9987\n",
            "Epoch 70/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.3637e-04 - accuracy: 1.0000 - val_loss: 132.3444 - val_accuracy: 0.0013\n",
            "Epoch 71/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.3459e-04 - accuracy: 1.0000 - val_loss: 101.5515 - val_accuracy: 0.0013\n",
            "Epoch 72/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.3472e-04 - accuracy: 1.0000 - val_loss: 231.7055 - val_accuracy: 0.0013\n",
            "Epoch 73/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.3020e-04 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9987\n",
            "Epoch 74/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.2877e-04 - accuracy: 1.0000 - val_loss: 30.0638 - val_accuracy: 0.0013\n",
            "Epoch 75/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.2715e-04 - accuracy: 1.0000 - val_loss: 0.6825 - val_accuracy: 0.9987\n",
            "Epoch 76/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.2666e-04 - accuracy: 1.0000 - val_loss: 216.4841 - val_accuracy: 0.0013\n",
            "Epoch 77/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.2306e-04 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9987\n",
            "Epoch 78/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.2214e-04 - accuracy: 1.0000 - val_loss: 519.3237 - val_accuracy: 0.0013\n",
            "Epoch 79/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.2243e-04 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9987\n",
            "Epoch 80/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.1942e-04 - accuracy: 1.0000 - val_loss: 31.2943 - val_accuracy: 0.0013\n",
            "Epoch 81/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.1913e-04 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.9987\n",
            "Epoch 82/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.1722e-04 - accuracy: 1.0000 - val_loss: 181.9045 - val_accuracy: 0.0013\n",
            "Epoch 83/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.1574e-04 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.9987\n",
            "Epoch 84/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.1490e-04 - accuracy: 1.0000 - val_loss: 122.9342 - val_accuracy: 0.0013\n",
            "Epoch 85/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.1311e-04 - accuracy: 1.0000 - val_loss: 396.1106 - val_accuracy: 0.0013\n",
            "Epoch 86/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.1226e-04 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9987\n",
            "Epoch 87/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.1043e-04 - accuracy: 1.0000 - val_loss: 47.6182 - val_accuracy: 0.0013\n",
            "Epoch 88/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.1030e-04 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9987\n",
            "Epoch 89/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.0903e-04 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9986\n",
            "Epoch 90/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.0745e-04 - accuracy: 1.0000 - val_loss: 142.1927 - val_accuracy: 0.0013\n",
            "Epoch 91/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.0705e-04 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9987\n",
            "Epoch 92/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.0459e-04 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9987\n",
            "Epoch 93/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.0498e-04 - accuracy: 1.0000 - val_loss: 767.0734 - val_accuracy: 0.0013\n",
            "Epoch 94/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.0287e-04 - accuracy: 1.0000 - val_loss: 0.5570 - val_accuracy: 0.9987\n",
            "Epoch 95/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.0198e-04 - accuracy: 1.0000 - val_loss: 29.8908 - val_accuracy: 0.0013\n",
            "Epoch 96/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.0189e-04 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9987\n",
            "Epoch 97/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 1.0041e-04 - accuracy: 1.0000 - val_loss: 15.2681 - val_accuracy: 0.0013\n",
            "Epoch 98/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 9.9683e-05 - accuracy: 1.0000 - val_loss: 132.7530 - val_accuracy: 0.0013\n",
            "Epoch 99/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 9.9169e-05 - accuracy: 1.0000 - val_loss: 582.1176 - val_accuracy: 0.0013\n",
            "Epoch 100/100\n",
            "285/285 [==============================] - 1s 2ms/step - loss: 9.8253e-05 - accuracy: 1.0000 - val_loss: 0.6691 - val_accuracy: 0.9987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIFd8_Vg5ktA",
        "outputId": "956116c1-1ce8-4e93-bb70-f10de8c90e2f"
      },
      "source": [
        "train_loss = network_history.history['loss']\n",
        "train_loss"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.48322248458862305,\n",
              " 0.05865254998207092,\n",
              " 0.032524023205041885,\n",
              " 0.02458585426211357,\n",
              " 0.018998952582478523,\n",
              " 0.014716763980686665,\n",
              " 0.01145606953650713,\n",
              " 0.00901416689157486,\n",
              " 0.007154915947467089,\n",
              " 0.005737293977290392,\n",
              " 0.004671027418226004,\n",
              " 0.0038710488006472588,\n",
              " 0.00325989443808794,\n",
              " 0.002777209272608161,\n",
              " 0.0023873494938015938,\n",
              " 0.002068295842036605,\n",
              " 0.0018046428449451923,\n",
              " 0.0015834941295906901,\n",
              " 0.0013970056315883994,\n",
              " 0.001240921439602971,\n",
              " 0.0011055876966565847,\n",
              " 0.0009908780921250582,\n",
              " 0.0008919076644815505,\n",
              " 0.0008061018888838589,\n",
              " 0.0007321432931348681,\n",
              " 0.0006676542689092457,\n",
              " 0.0006112927803769708,\n",
              " 0.0005617622518911958,\n",
              " 0.0005176729755476117,\n",
              " 0.00047926357365213335,\n",
              " 0.00044435987365432084,\n",
              " 0.0004136626666877419,\n",
              " 0.0003861935983877629,\n",
              " 0.00036188209196552634,\n",
              " 0.0003393253718968481,\n",
              " 0.0003209804417565465,\n",
              " 0.0003021145239472389,\n",
              " 0.00028628387372009456,\n",
              " 0.00027278397465124726,\n",
              " 0.00026024706312455237,\n",
              " 0.0002481773553881794,\n",
              " 0.00023986278392840177,\n",
              " 0.00022915574663784355,\n",
              " 0.00022092786093708128,\n",
              " 0.00021418703545350581,\n",
              " 0.00020719693566206843,\n",
              " 0.00020091138139832765,\n",
              " 0.00019623614207375795,\n",
              " 0.0001911202271003276,\n",
              " 0.00018615556473378092,\n",
              " 0.00018378788081463426,\n",
              " 0.00017919970559887588,\n",
              " 0.0001756588462740183,\n",
              " 0.0001724593894323334,\n",
              " 0.00016960622451733798,\n",
              " 0.00016730124480091035,\n",
              " 0.00016337598208338022,\n",
              " 0.0001608282618690282,\n",
              " 0.00015841373533476144,\n",
              " 0.0001566796563565731,\n",
              " 0.00015327896107919514,\n",
              " 0.00015152509149629623,\n",
              " 0.00014904237468726933,\n",
              " 0.0001469510461902246,\n",
              " 0.00014538675895892084,\n",
              " 0.0001426465023541823,\n",
              " 0.00014157906116452068,\n",
              " 0.0001392838457832113,\n",
              " 0.0001374869461869821,\n",
              " 0.00013552021118812263,\n",
              " 0.00013479955669026822,\n",
              " 0.00013242200657259673,\n",
              " 0.00012999404862057418,\n",
              " 0.0001285654871026054,\n",
              " 0.00012719536607619375,\n",
              " 0.00012583057105075568,\n",
              " 0.00012462622544262558,\n",
              " 0.00012238715135026723,\n",
              " 0.00012133079872000962,\n",
              " 0.0001198800528072752,\n",
              " 0.00011898125376319513,\n",
              " 0.00011695166904246435,\n",
              " 0.00011588480992941186,\n",
              " 0.0001145963033195585,\n",
              " 0.00011324995284667239,\n",
              " 0.00011186592018930241,\n",
              " 0.00011032162728952244,\n",
              " 0.00011048710439354181,\n",
              " 0.00010973920143442228,\n",
              " 0.00010736608237493783,\n",
              " 0.00010683698928914964,\n",
              " 0.0001048619524226524,\n",
              " 0.00010449182445881888,\n",
              " 0.00010292667866451666,\n",
              " 0.0001017551840050146,\n",
              " 0.00010135616321349517,\n",
              " 0.00010032152204075828,\n",
              " 0.00010015474981628358,\n",
              " 9.810849587665871e-05,\n",
              " 9.72227135207504e-05]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjNAtexZKW9h",
        "outputId": "263c5f82-506a-49b3-fdfc-ed3fcd9ae527"
      },
      "source": [
        "\n",
        "val_loss = network_history.history['val_loss']\n",
        "val_loss"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[173.13441467285156,\n",
              " 241.72230529785156,\n",
              " 236.75982666015625,\n",
              " 215.91403198242188,\n",
              " 187.3443145751953,\n",
              " 150.81394958496094,\n",
              " 115.01757049560547,\n",
              " 81.07572937011719,\n",
              " 51.99166488647461,\n",
              " 29.82811737060547,\n",
              " 16.171245574951172,\n",
              " 8.074575424194336,\n",
              " 3.944622039794922,\n",
              " 1.3243850469589233,\n",
              " 0.6388529539108276,\n",
              " 0.29561811685562134,\n",
              " 0.06719523668289185,\n",
              " 0.24388094246387482,\n",
              " 0.4035508632659912,\n",
              " 1.1063570976257324,\n",
              " 0.7064515352249146,\n",
              " 0.22711125016212463,\n",
              " 0.4571582078933716,\n",
              " 0.7615072131156921,\n",
              " 0.15022768080234528,\n",
              " 0.15250854194164276,\n",
              " 0.24682565033435822,\n",
              " 0.377416729927063,\n",
              " 0.4272928237915039,\n",
              " 0.491597980260849,\n",
              " 0.7334501147270203,\n",
              " 0.09544374793767929,\n",
              " 0.6205377578735352,\n",
              " 0.6964139938354492,\n",
              " 0.4004712402820587,\n",
              " 0.8616730570793152,\n",
              " 2.0620498657226562,\n",
              " 12.720890998840332,\n",
              " 1.0782040357589722,\n",
              " 6.649407386779785,\n",
              " 4.5050811767578125,\n",
              " 273.1871032714844,\n",
              " 0.07455038279294968,\n",
              " 0.16664208471775055,\n",
              " 398.1741027832031,\n",
              " 0.3926343321800232,\n",
              " 0.6077594757080078,\n",
              " 166.97486877441406,\n",
              " 0.3056230843067169,\n",
              " 215.46949768066406,\n",
              " 0.12082596868276596,\n",
              " 0.6559858918190002,\n",
              " 99.87274169921875,\n",
              " 0.49795088171958923,\n",
              " 0.0486561544239521,\n",
              " 0.1224261149764061,\n",
              " 274.2642822265625,\n",
              " 0.1584790199995041,\n",
              " 0.02334795705974102,\n",
              " 0.31945374608039856,\n",
              " 138.06610107421875,\n",
              " 153.9266815185547,\n",
              " 352.1515197753906,\n",
              " 0.02698507346212864,\n",
              " 0.7223188877105713,\n",
              " 0.0687078982591629,\n",
              " 0.09170359373092651,\n",
              " 0.0811525359749794,\n",
              " 0.02133595570921898,\n",
              " 132.3444061279297,\n",
              " 101.55150604248047,\n",
              " 231.70547485351562,\n",
              " 0.25256961584091187,\n",
              " 30.06377410888672,\n",
              " 0.6824832558631897,\n",
              " 216.48410034179688,\n",
              " 0.06048199534416199,\n",
              " 519.3236694335938,\n",
              " 0.1365804821252823,\n",
              " 31.29429054260254,\n",
              " 0.337263286113739,\n",
              " 181.9044952392578,\n",
              " 0.3778204321861267,\n",
              " 122.93423461914062,\n",
              " 396.110595703125,\n",
              " 0.04950660094618797,\n",
              " 47.618167877197266,\n",
              " 0.09835563600063324,\n",
              " 0.02732335589826107,\n",
              " 142.1927032470703,\n",
              " 0.06623342633247375,\n",
              " 0.1564503014087677,\n",
              " 767.0734252929688,\n",
              " 0.5569959282875061,\n",
              " 29.890796661376953,\n",
              " 0.17015381157398224,\n",
              " 15.268075942993164,\n",
              " 132.75296020507812,\n",
              " 582.1175537109375,\n",
              " 0.6691365838050842]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0pebrdTKeRx",
        "outputId": "269c5eb0-4421-47a9-ee7d-84efa1b98f70"
      },
      "source": [
        "model.predict(x_test)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.5133411e-06],\n",
              "       [1.5342495e-06],\n",
              "       [1.9571523e-06],\n",
              "       ...,\n",
              "       [1.8927104e-06],\n",
              "       [1.8121116e-06],\n",
              "       [1.4666518e-06]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIQvrBs1Kj1E",
        "outputId": "0c7a8b7e-6b56-42f4-9caf-1ac9be051c81"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2670/2670 [==============================] - 4s 1ms/step - loss: 9.9795e-05 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.979516471503302e-05, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0_4zWgmKoaI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}